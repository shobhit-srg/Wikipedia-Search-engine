# -*- coding: utf-8 -*-
"""Untitled7.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Zy2KsM-TvKc0JcJ6T9ZKasVKKo3SLuZx
"""

from google.colab import drive
drive.mount('/content/gdrive')
root_path = 'gdrive/My Drive/IRE/'

from os import listdir
from os.path import isfile, join
onlyfiles = [f for f in listdir(root_path) if isfile(join(root_path, f))]
print(onlyfiles)

# root_path = '/home/srg/Desktop/3sem/IRE/MP1/'
import sys
import xml.sax
import xml.parsers.expat
import time 
import pickle
from collections import OrderedDict
start=time.time()
# root_path=sys.argv[1]
# index_loc=sys.argv[2]
# indexstat_loc=sys.argv[3]
title_array=[]
token_count=[]
text_array=[]
inverted_index={}
total_xml_count=0
tc=0
stemming_word={}
field=["t","c","i","l","r","b"]
class ParseHandler(xml.sax.handler.ContentHandler):
  def __init__(self):
    global tc
    self.count=tc
    self.curpath = []
    self.CurrentData = ""
    self.title = ""
    self.text = ""
    self.f=0
    self.title_words=defaultdict(int)
    self.cat_words=defaultdict(int)
    self.info_words=defaultdict(int)
    self.link_words=defaultdict(int)
    self.body_words=defaultdict(int)
    self.ref_words=defaultdict(int)
    self.remain_words=defaultdict(int)
  def startElement(self, name, attrs):
    # print(name,attrs)
    self.CurrentData = name
    if name == "page":
      self.f = self.f + 1
      # print(self.f)

  # indexing in inverted list start from 1
  def endElement(self, name):
    flag=0
    global tc
    # print(self.CurrentData)
    if self.CurrentData == "title":
      self.count = self.count + 1
      if(self.count%1000==0):
         print(self.count,time.time()-start) 
      title_array.append(self.title.lower())
      # print(tc,title_array[tc])   
      tc=self.count
      # print(self.count)
      # print("tit",self.count,self.title)
      self.title_words=pre_process_title(self.title)
    elif self.CurrentData == "text":
      if "#REDIRECT" not in self.text:
        self.cat_words,self.info_words,self.link_words,self.ref_words,self.remain_words=pre_process_text(self.text)
      # print(self.cat_words)
      # print(self.info_words)
      # print(self.link_words)
      # print(self.ref_words)
      # text_array.append(self.text)
      self.text= ""
      if len(self.title_words)>0:
        for w in self.title_words:
          s=str(self.count)+str(field[flag])+str(self.title_words[w])
          lst=[s]
          # print(w,lst)
          if w not in inverted_index:
            inverted_index[w]=[]
          inverted_index[w].extend(lst)
      flag=1
      if len(self.cat_words)>0:
        for w in self.cat_words:
          s=str(self.count)+str(field[flag])+str(self.cat_words[w])
          lst=[s]
          # print(w,lst)
          if w not in inverted_index:
            inverted_index[w]=[]
          inverted_index[w].extend(lst)
      flag=2
      if len(self.info_words)>0:
        for w in self.info_words:
          s=str(self.count)+str(field[flag])+str(self.info_words[w])
          lst=[s]
          # print(w,lst)
          if w not in inverted_index:
            inverted_index[w]=[]
          inverted_index[w].extend(lst)
      flag=3
      if len(self.link_words)>0:
        for w in self.link_words:
          s=str(self.count)+str(field[flag])+str(self.link_words[w])
          lst=[s]
          # print(w,lst)
          if w not in inverted_index:
            inverted_index[w]=[]
          inverted_index[w].extend(lst)
      flag=4
      if len(self.ref_words)>0:
        for w in self.ref_words:
          s=str(self.count)+str(field[flag])+str(self.ref_words[w])
          lst=[s]
          # print(w,lst)
          if w not in inverted_index:
            inverted_index[w]=[]
          inverted_index[w].extend(lst)
      flag=5
      if len(self.remain_words)>0:
        for w in self.remain_words:
          s=str(self.count)+str(field[flag])+str(self.remain_words[w])
          lst=[s]
          # print(w,lst)
          if w not in inverted_index:
            inverted_index[w]=[]
          inverted_index[w].extend(lst)
      # print(inverted_index)
    self.CurrentData= ""

  def characters(self, data):
    if self.CurrentData == "title":
      self.title = data
    elif self.CurrentData == "text":
      self.text += data


from collections import defaultdict
import re
from spacy.lang.en.stop_words import STOP_WORDS
import nltk
import string 
def Num_punch_removal(wordlist):
  fr=0
  res=[]
  for wrd in wordlist:
    s = ""
    for w1 in wrd:
      if w1 in set(["0", "1", "2", "3", "4", "5", "6", "7", "8", "9"]):
        fr=fr+1
        continue
      if w1 in set(list(string.punctuation) + ['\n', '\t', " "]):
        if len(s) and s.isalpha():
            res.append(s)
        s = ""
        continue
      s += w1
    if len(s) and s.isalpha():
      res.append(s)
  return res

stemmer = nltk.stem.SnowballStemmer('english')
# stemmer = nltk.stem.PorterStemmer()

def hasNumbers(inputString):
  return any(char.isdigit() for char in inputString)

def stop_words(wordlist):
  res=[]
  for w in wordlist:
    if len(w) <= 1 or w in STOP_WORDS:
      continue
    if "www" in w or "https" in w or "net" in w or "com" in w:
      continue
    if(hasNumbers(w)):
      continue
    if w in stemming_word:
      res.append(stemming_word[w])
    else:  
      w1=stemmer.stem(w)
      stemming_word[w]=w1
      res.append(w1)
  return res




from nltk.stem import WordNetLemmatizer
p = re.compile("[^a-zA-Z]")

def pre_process_title(title):
  title=title.lower()
  title+="\n"
  tokens = re.findall("\d+|[\w]+",title)
  # token=re.split(p,title)
  global total_xml_count
  tokens = [i.lower() for i in tokens]
  total_xml_count += len(tokens)
  token1 = Num_punch_removal(tokens)
  token2 = stop_words(token1)
  # print(token2)
  title_words=defaultdict(int)
  for w in token2:
    if w != "":
      title_words[w]=title_words[w]+1
  return title_words  


def pre_process_text(text):
  # print(text)
  # category ki list
  cat_words=defaultdict(int)
  info_words=defaultdict(int)
  link_words=defaultdict(int)
  body_words=defaultdict(int)
  ref_words=defaultdict(int)
  body_words1=defaultdict(int)
  global total_xml_count
  cat=re.findall("\[\[Category:(.*?)\]\]",text)
  # print(cat)
  total_xml_count += len(cat)
  cat = Num_punch_removal(cat)
  # print(cat1)
  # cat_str=""
  # for w in cat:
    # cat_str += w
  # cat=re.split(r'[^A-Za-z0-9]+',cat_str)
  cat2 = stop_words(cat)
  cat2 = [i.lower() for i in cat2]
  # print("cat2",cat2)
  for w in cat2:
    cat_words[w]=cat_words[w]+1

  # infobox ki list
  info=[]
  info_str = ""
  info_array = text.split("{{Infobox")
  if len(info_array) > 1:
    info_array=info_array[1:]
    # print(info_array)
    for i in range(len(info_array)):
      element=info_array[i].split('\n')
      for line in element:
        if line == "}}":
          break
        info_str += line      
  info_tokens=re.split(r'[^A-Za-z0-9]+', info_str)
  total_xml_count  += len(info_tokens)
  # print(info_tokens)
  # info_tokens = Num_punch_removal(info_tokens)
  info_t2 = stop_words(info_tokens)
  info_t2 = [i.lower() for i in info_t2]
  r2 = re.compile(r'{{infobox(.*?)}}',re.DOTALL)

  for w in info_t2:
    if w not in info_words:
      info_words[w]=0
    info_words[w] = info_words[w] + 1
  
  # links ki lists
  # text=text.lower()
  link_string=""
  links=text.split("== External links ==")
  # print(len(links))
  if len(links) > 1:
    links=links[1].split("\n")
    # print("l.",links)
    for line in links:
      if line and line[0]=='*':
        link_string += line
  
  links1=text.split("==External links==")
  if len(links1) > 1:
    links1=links1[1]
    links1=links1.split("\n")
    # print(links)
    for line in links1:
      if line and line[0]=='*':
        link_string += line
    
  link_tok = re.split(r'[^A-Za-z0-9]+', link_string)
  total_xml_count += len(link_tok)
  # link_tok = Num_punch_removal(link_tok)
  link_t2 = stop_words(link_tok)
  link_t2 = [i.lower() for i in link_t2]
  r1 = re.compile(r'\[\[Category:(.*?)\]\]',re.DOTALL)
  for w in link_t2:
    link_words[w]=link_words[w]+1


 # references ki list
  # text=text.lower()
  refs=text.split("==References==")
  ref_str=""
  if len(refs)>1:
    refs=refs[1]
    # print(refs)
    refs=refs.split("==")
    ref_str=refs[0]
  ref_tok = re.split(r'[^A-Za-z0-]+9', ref_str)
  total_xml_count += len(ref_tok)
  ref_tok = Num_punch_removal(ref_tok)
  ref_t2 = stop_words(ref_tok)
  ref_t2 = [i.lower() for i in ref_t2]

  for w in ref_t2:
    if w =="reflist" or w == "ref" or w == "name":
      continue
    ref_words[w]=ref_words[w]+1

  # full_body_tok = re.split(r'[^A-Za-z0-9]+', text)
  # f_body_t1 = Num_punch_removal(full_body_tok)
  # f_body_t2 = stop_words(f_body_t1)
  # f_body_t2 = [i.lower() for i in f_body_t2]

  # for w in f_body_t2:
    # body_words[w]=body_words[w]+1
  
  body = r1.sub(' ', text)
  r3 = re.compile(r'{{')
  body = r2.sub(' ', body)
  body = r3.sub(' ', body)
  body_tok1 = re.split(r'[^A-Za-z0-9]+', body)
  total_xml_count += len(body_tok1)
  table = str.maketrans('', '', string.punctuation)
  body_tok1 = [w.translate(table) for w in body_tok1]
  body_t2_1 = stop_words(body_tok1)
  body_t2_1 = [i.lower() for i in body_t2_1]
  for w in body_t2_1:
    body_words1[w]=body_words1[w]+1
  
  
  # print(cat_words)
  # print(info_words) 
  # print(link_words)  
  # print(ref_words)
  # print(body_words1)
  # print(body_words)
  return cat_words,info_words,link_words,ref_words,body_words1

# print(len(title_array))
# print(title_array)
# print(len(text_array))

# import os
# if not os.path.exists(index_loc):
    # os.makedirs(index_loc)
# fout = index_loc+"Index.txt"


# fout = root_path+"InvertedIndex.txt"
# fo = open(fout, "w")

# def listToString(s):   
#   str1 = " "   
#   return (str1.join(s)) 
# for k, v in inverted_index.items():
#   x=listToString(v)
#   x=x.replace(" ",",")
#   fo.write(str(k) + ':'+ x + '\n')
# fo.close()

import os
def listToString(s):   
  str1 = " "   
  return (str1.join(s)) 
def wr(dict,I):
  root_path1 = 'gdrive/My Drive/Index/'
  fout = os.path.join(root_path1+I)
  fo = open(fout, "w")      
  for k, v in dict.items():
    x=listToString(v)
    x=x.replace(" ",",")
    fo.write(str(k) + ':'+ x + '\n')
  fo.close()

import time
s1=time.time()
parser = xml.sax.make_parser()
parser.setFeature(xml.sax.handler.feature_namespaces, 0) 
Handler = ParseHandler()
parser.setContentHandler(Handler)
inverted_index={}
parser.parse(root_path+'enwiki-20200801-pages-articles-multistream1.xml-p1p30303')
I1 = OrderedDict(sorted(inverted_index.items())) 
wr(I1,"I1.txt")
print("1")
inverted_index={}
parser.parse(root_path+'enwiki-20200801-pages-articles-multistream2.xml-p30304p88444')
I2 = OrderedDict(sorted(inverted_index.items()))
print("2")
wr(I2,"I2.txt")
inverted_index={}
parser.parse(root_path+'enwiki-20200801-pages-articles-multistream3.xml-p88445p200509')
I3 = OrderedDict(sorted(inverted_index.items()))
print("3")
wr(I3,"I3.txt")
inverted_index={}
# parser.parse(root_path+'enwiki-20200801-pages-articles-multistream4.xml-p200510p352689')
# I4 = OrderedDict(sorted(inverted_index.items()))
# print("4")
# wr(I4,"I4.txt")

# inverted_index={}
# parser.parse(root_path+'enwiki-20200801-pages-articles-multistream5.xml-p352690p565313')
# I5 = OrderedDict(sorted(inverted_index.items()))
# wr(I5,"I5.txt")

print('tc',tc)
print("time",time.time()-s1)

print(tc)

root_path1 = 'gdrive/My Drive/Index/'
indexes = [f for f in listdir(root_path1) if isfile(join(root_path1, f))]
print("ilu",indexes)
# print(indexes[0][1:-4]+indexes[0+1][1:-4])

root_path1 = 'gdrive/My Drive/Index/'
indexes = [f for f in listdir(root_path1) if isfile(join(root_path1, f))]
print("ilu",indexes)
# print(indexes[0][1:-4]+indexes[0+1][1:-4])


# f1 = os.path.join(root_path1+indexes[i])
# fo1 = open(f1, "r")
# l1=fo1.readline().split('\n')
# while l1:
  # print(l1)
  # print("lulululuuluul")
  # l1=fo1.readline()[:-1]

while(len(indexes)>1):
  for i in range(0,len(indexes),2):
    if(i+1==len(indexes)):
      break
    f1 = os.path.join(root_path1+indexes[i])
    fo1 = open(f1, "r")
    f2 = os.path.join(root_path1+indexes[i+1])
    fo2 = open(f2, "r")
    s=indexes[i][1:-4]+indexes[i+1][1:-4]
    fq = os.path.join(root_path1+'I'+s+'.txt')
    fw = open(fq, "w")
    l1=fo1.readline()
    l1=l1[:-1]
    l2=fo2.readline()
    l2=l2[:-1]
    while l1 and l2:
      w1,p1=l1.split(":")
      w2,p2=l2.split(":")
      if w1 == w2:
        fw.write(w1+":"+p1+","+p2+'\n')
        l1=fo1.readline()
        l1=l1[:-1]
        l2=fo2.readline()
        l2=l2[:-1]
      else:
        if w1 < w2:
          fw.write(w1+":"+p1+'\n')
          l1=fo1.readline()
          l1=l1[:-1]
        elif w2 < w1:
          fw.write(w2+":"+p2+'\n')
          l2=fo2.readline()
          l2=l2[:-1]
    while l1:
      fw.write(w1+":"+p1+'\n')
      l1=fo1.readline()
      l1=l1[:-1]
    while l2:
      fw.write(w2+":"+p2+'\n')
      l2=fo2.readline()
      l2=l2[:-1]
    fo1.close()
    fo2.close()
    fw.close() 
    os.remove(f1)
    os.remove(f2)
  indexes = [f for f in listdir(root_path1) if isfile(join(root_path1, f))]
  print(indexes)

def p(s,file):
  flag=0
  s1 = ""
  for line in file:
    w=line.split(":")[0]
    if s == w:
      flag=1
      if flag == 1:
        for ch in line:
				  # print(ch,end="")
          s1 += ch
          if ch is '\n':
            flag=0
            return s1

s='sachin'
print(s)
file = open(root_path1+'I1.txt', 'r')
q=p(s,file)
file.close()
file = open(root_path1+'I2.txt', 'r')
q1=p(s,file)
file.close()
file = open(root_path1+'I12.txt', 'r')
q2=p(s,file)
file.close()
file = open(root_path1+'I3.txt', 'r')
q3=p(s,file)
file.close()
file = open(root_path1+'I4.txt', 'r')
q4=p(s,file)
file.close()
file = open(root_path1+'I34.txt', 'r')
q5=p(s,file)
file.close()
file = open(root_path1+'I5.txt', 'r')
q6=p(s,file)
file.close()
file = open(root_path1+'I512.txt', 'r')
q7=p(s,file)
file.close()
file = open(root_path1+'I34512.txt', 'r')
q8=p(s,file)

print(q)
print(q1)
# print(q2)
print(q3)
print(q4)
# print(q5)
print(q6)
# print(q7)
print(q8)

file.close()

e1=q.split(":")[1]
e2=q1.split(":")[1]
e3=q2.split(":")[1]
r1=e1.split(",")
r2=e2.split(",")
r3=e3.split(",")

e4=q3.split(":")[1]
e5=q4.split(":")[1]
e6=q5.split(":")[1]
r4=e4.split(",")
r5=e5.split(",")
r6=e6.split(",")

e7=q6.split(":")[1]
e8=q7.split(":")[1]
e9=q8.split(":")[1]
r7=e7.split(",")
r8=e8.split(",")
r9=e9.split(",")

print(len(r1))
print(len(r2))
# print(len(r3))
print(len(r4))
print(len(r5))
# print(len(r6))
print(len(r7))
# print(len(r8))
print(len(r9))

root_path2 = 'gdrive/My Drive/split_index/'
# file = open(root_path2+'I34512.txt', 'r')
f1 = os.path.join(root_path1+'I312.txt')
fo1 = open(f1, "r")
sec=[]
threshold=20000
c=0
line = fo1.readline()
l1 = line[:-1]
print(l1.split(":")[0])
sec.append(l1.split(":")[0])
fi=0
fw1 = os.path.join(root_path2+str(fi)+".txt")
fw = open(fw1, "w")
fw.write(line)
tic=0
while line:
  # print(line)
  tic = tic + 1
  line=fo1.readline()
  c=(c+1) % threshold
  if c==0:
    fw.close()
    fi=fi+1
    # print(tic,fi)
    fw1 = os.path.join(root_path2+str(fi)+".txt")
    fw = open(fw1, "w")
    fw.write(line)
    l1=line[:-1]
    # print(l1.split(":")[0])
    sec.append(l1.split(":")[0])
  else:
    fw.write(line)
fw.close()


print(tic)

fw1 = os.path.join(root_path2+"sec_ind.txt")
fw = open(fw1, "w")
fw.write(str(sec))
fw.close()

print(sec)

def which_file(wrd):
  val=len(sec)-1
  for i in range(0,len(sec)-1):
    if wrd >= sec[i] and wrd < sec[i+1]:
      val=i
      break
  return val

# q="2,world"
def rpl(w):
  val=which_file(w)
  # print(val)
  file = open(root_path2+str(val)+'.txt', 'r')
  # print(w)
  pl=p(w,file)
  file.close()
  pl=pl[:-1]
  pl=pl.split(":")[1]
  # print(pl)
  pl=pl.split(",")
  # print(pl)
  return pl


def query_parse(q):
  flag=0
  if ":" not in q:
    flag=1
    k,qq=q.split(",")
    q1=qq.split()
    return k,flag,q1
  k,q=q.split(",")
  q=q.lower().split(":")
  # print(q)
  q1=[]
  if(len(q)==2):
    q1.append(q[0]+":"+q[1])
  else:
    q1.append(q[0]+":"+q[1][:-2])
  for i in range(1,len(q)-1):
    s=""
    if(i+1==len(q)-1):
      s+=q[i][-1]+":"+q[i+1]
    else:
      s+=q[i][-1]+":"+q[i+1][:-2]
    q1.append(s)
  
  # print(q1)
  return k,flag,q1
# pl = posting list
# N1 = document dict to store tfidf

k,flag,q1=query_parse("25,i:sachin i:tendulkar")
print(k,flag,q1)

# N=[]
# N1={}
# N2={}
# for wrd in pl:
  # s=""
  # for i in wrd:
    # if i.isalpha():
      # if s not in N:
        # N.append(s)
        # N1[s]=[]
        # N2[s]=0
    # else:
      # s+=i
# 
# print(N)
# print(N1)
tfidf=defaultdict(float)
field=["t","c","i","l","r","b"]
import math
import operator
global tc
if flag==1:
  for query in q1:
    pl=rpl(query)
    # print(query,pl)
    N=[]
    N1={}
    N2={}
    for w in pl:
      s=""
      for i in w:
        if i.isalpha():
          if s not in N:
            N.append(s)
            N1[s]=[]
            N2[s]=0
        else:
          s+=i
    # print(N1)
    # print(N2)
    for doc in pl:
      for f in field:
        if f in doc:
          d,c=doc.split(f)
          N2[str(d)] += int(c)
          if f=="t":
            N2[str(d)] += int(c)*2000
          if f=="i":
            N2[str(d)] +=int(c)*2
    # print(N2)
    term_tfidf={}
    d={}
    idf=math.log2(tc/len(N))
    for i in N2:
      term_tfidf[i]=idf*math.log1p(N2[i])
      tfidf[i] += term_tfidf[i]
    term_tfidf = dict(sorted(term_tfidf.items(), key=operator.itemgetter(1),reverse=True))
    # print(term_tfidf)
  tfidf = dict(sorted(tfidf.items(), key=operator.itemgetter(1),reverse=True))
  print(tfidf)

elif flag==0:
  for q in q1:
    f,query=q.split(":")
    pl=rpl(query)
    print(query,pl)
    N=[]
    N1={}
    N2={}
    for w in pl:
      s=""
      for i in w:
        if i.isalpha():
          if s not in N:
            N.append(s)
            N1[s]=[]
            N2[s]=0
        else:
          s+=i
    for doc in pl:
      if f in doc:
        d,c=doc.split(f)
        N2[str(d)] += int(c)
        if f=="t":
          N2[str(d)] += int(c)*2000
        if f=="i":
          N2[str(d)] +=int(c)*2
    term_tfidf={}
    d={}
    idf=math.log2(tc/len(N))
    for i in N2:
      term_tfidf[i]=idf*math.log1p(N2[i])
      tfidf[i] += term_tfidf[i]
    term_tfidf = dict(sorted(term_tfidf.items(), key=operator.itemgetter(1),reverse=True))
    print(term_tfidf)
  tfidf = dict(sorted(tfidf.items(), key=operator.itemgetter(1),reverse=True))
  print(tfidf)

  # print(len(title_array))
def getList(dict): 
    list = [] 
    for key in dict.keys(): 
        list.append(int(key)) 
    return list

k_title=getList(tfidf)

for i in range(int(k)):
  x=int(k_title[i])
  print(x,title_array[x-1])

